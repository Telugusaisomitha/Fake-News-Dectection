# -*- coding: utf-8 -*-
"""Fake News Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bp8yM6z8mEBViP1sMsCpzCUcX-7hq0i2

#Fake News Detection

**Importing Libraries**
"""

# Importing necessary libraries

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

"""**Load the Dataset**"""

# Load the dataset
train_df = pd.read_csv('/content/train[1].csv')
train_df

"""**Data Exploration**"""

#Headings

train_df.head()

#Tail or Bottom lines

train_df.tail()

#Info

train_df.info()

#Shape

train_df.shape

#Describe

train_df.describe()

#Getting Labels

train_df.Label

#Getting Statements

train_df.Statement

#Removing Null Values

train_df.dropna()

#Data Quality Check

def data_qualityCheck():
    print("Checking data qualitites...")
    train_df.isnull().sum()
    train_df.info()
    print("check finished.")
data_qualityCheck()

"""**Data Visualization**"""

#Bar plot

plt.figure(figsize=(8, 6))
sns.countplot(x='Label', data=train_df, alpha=0.5)
plt.title('Distribution of Labels')
plt.xlabel('Label')
plt.ylabel('Count')
plt.show()

"""**Training the Dataset**"""

# Splitting data into features and labels

X = train_df['Statement']
Y = train_df['Label']
X,Y

# Initialize TF-IDF Vectorizer

tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
tfidf_vectorizer

# Fit and transform the data

X_tfidf = tfidf_vectorizer.fit_transform(X)
X_tfidf

#Split the data into training and testing sets

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
X,Y

# Feature Engineering (TF-IDF Vectorization)

tfidf_matrix = tfidf_vectorizer.fit_transform(train_df['Statement'])

#Initialize PassiveAggressiveClassifier

pac = PassiveAggressiveClassifier(max_iter=50)

#Train the model

pac.fit(tfidf_matrix, train_df['Label'])

# Predict labels

Y_pred = pac.predict(X_tfidf)
Y_pred

# Calculate accuracy

accuracy = accuracy_score(Y, Y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Confusion Matrix

conf_matrix = confusion_matrix(Y, Y_pred)
print('Confusion Matrix:')
print(conf_matrix)

#Heatmap for Confusion Matrix

sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', xticklabels=['FAKE Data', 'REAL Data'], yticklabels=['FAKE Data', 'REAL Data'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Function to predict whether a statement is fake or real

def predict_statement(statement):
    statement_tfidf = tfidf_vectorizer.transform([statement])
    prediction = pac.predict(statement_tfidf)
    if prediction == 1:
        return "False"
    else:
        return "True"

# Output

Statement = "The earth is flat."
prediction = predict_statement(Statement)
print(f"Prediction for the statement '{Statement}': {prediction}")

"""**Conclusion and Insights**

1.Accuracy: 0.97

2.Confusion_Matrix: [[4331  157]
 [ 127 5625]]

3.Hence OUTPUT: Prediction for the statement 'The earth is flat.': False
"""